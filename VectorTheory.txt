I am wondering what the correlation is between imaginary arithmetic
and vector arithmetic.  Is there a way of defining vector arithmetic
that is isomorphic to imaginary arithmetic?  If so, how would such
a system conceptually include things like raising a real number to a complex
number?

In the following document,  I will use the following convention:

A capital letter symbolizes an arbitrary vector; a lowercase
letter symbolizes a scalar.  The exception to this is the letter
R, which I will usually subscript with another letter, which I use
to symbolize the radius (or magnitude) of a given vector.

E.g., V is a vector whereas v is a scalar
V1 + V1 = V3 indicates vector addition whereas a + b = c indicates scalar addition
Rv is the radius or magnitude of vector V

Let's consider an imaginary number to be simply a vector Vi = (x, y)

-----------------------------------------------------------------------
            VECTOR-VECTOR ADDITION & SUBTRACTION DEFINITION
-----------------------------------------------------------------------
If V1 = (a, b) and V2 = (c, d), and I1 = (a, bi) and I2 = (c, di),
How does V1 + V2 relate to I1 + I2?
How does V1 - V2 relate to I1 - I2?
These questions are equivalent to the following:
How does (a, b) + (c, d) correlate to (a, bi) + (c, di)?
How does (a, b) - (c, d) correlate to (a, bi) - (c, di)?

These are obviously isomorphic.  It's less obvious however, how to create
vector multiplication and division functions which are isomorphic to
imaginary arithmetic.

--------------------------------------------------------------------------
                         IDENTITY VECTORS
--------------------------------------------------------------------------
I'll stop here to note that we must define a 0 vector and an identity vector,
which must satisfy the properties:
V0 + X = X + V0 = X for all X
I * X = X * I for all X

For convenience's sake, we will define an alternative identity vector
I' to simplify the shorthand of defining a vector with only a complex component.
We will write this as I'; in truth, this is just a complex vector
C = [0, iθ].

The zero vector is easy; it is simply the vector (0, 0).  As will be seen
later when we define our system of multiplication, the identity vector will
be (1, 0) (this tends to be true when we map scalar values onto our
vector field - a scalar will usually be mapped onto the complex plane
by setting its complex, or y value, to 0)

--------------------------------------------------------------------------
                   SCALAR MULTIPLICATION ISOMORPHISM
--------------------------------------------------------------------------

We must define a system of vector multiplication whereby:
V1 * V2 is isomorphic to I1 * I2
V1 / V2 is isomorphic to I1 / I2

It won't be the dot product, since that returns a scalar.
It won't be the cross product, since that returns a vector perpendicular
to the two vectors, and we want a method that returns a vector in the
same plane.

--------------------------------------------------------------------------
              VECTOR-VECTOR MULTIPLICATION ISOMORPHISM CHECK
--------------------------------------------------------------------------

We would like our vector multiplication to meet the following requirement:
if X = V * W, |X| = |V| * |W|

--------------------------------------------------------------------------
              VECTOR-VECTOR MULTIPLICATION
--------------------------------------------------------------------------

Let us investigate vector-vector multiplication and see whether it is,
in fact, isomorphic to vector-scalar multiplication.

For the angle, we need to consider the fact that the vector I' will
never scale our vector.  It will, however rotate it by 90 degrees.
This can be seen from I1 * I' = I2:  (a, bi) * (0, i) = (-b, ai).
I2 can be seen to have the same magnitude as I1, but with a 90 degree rotation.

We can also see that any purely real vector will never rotate our vector.
It will, however, scale it by its magnitude
This can be seen from I1 * I' = I2:  (a, bi) * (c, 0) = (c * a, c * bi)
02 = atan(c * b / c * a) = atan(b / a) = 01

Next, since (A * B) * C = A * (B * C),
if B = (n, 0) and C = I'
(A * B) * C = A scaled by n and rotated by 90 degrees.
However, (B * C) = (0, ni)
Therefore, A * (0, ni) will scale A by n and rotate it by 90 degrees.
Therefore, multiplication of a purely complex vector will rotate by 90 degrees
and scale by the magnitude.

Finally, let us look at  A * (B + C) where B = (n, 0) and C = (0, mi)
A * (B + C) = A * B + A * C
A * B = A scaled by n
A * C = A scaled by m and rotated by 90 degrees
These two vectors summed together form a right triangle whose magnitude is |A| * (m^2 + n^2) ^ /.5
and whose angle is 0a + atan(m / n)

However, if we define a vector D = B + C, we will find that |D| = (m^2 + n^2) ^ /.5 and 0d = atan(m / n)

This gives us a definition of the multiplication of two vectors:

--------------------------------------------------------------------------
             VECTOR-VECTOR MULTIPLICATION - DEFINITION
--------------------------------------------------------------------------
A * B = C where |C| = |A| * |B| and 0c = 0a + 0b



Since we constrained the output of our multiplication to match
what happens in the complex numbers, this definition of vector multiplication
is exactly isomorphic to the multiplication of complex numbers.

And, if we look earlier in our derivation, we can see that this has the
property we were hoping for - namely, that the magnitude output of this
function is the same as the magnitude output of scalar-scalar multiplication.


--------------------------------------------------------------------------
                 VECTOR-VECTOR DIVISION - DEFINITION
--------------------------------------------------------------------------

How would division work in such a system?
if V3 = V1 * V2, then V3 / V1 = V2 and V3 / V2 = V1

What operation gives this?  Simply the reverse of multiplication:
For any X = V / W:
|X| = |V| / |W|
θX = θV - θW mod 2pi

--------------------------------------------------------------------------
                VECTOR-SCALAR MULTIPLICATION DEFINITION
--------------------------------------------------------------------------

From this, scalar multiplication and division of a vector are simple (once
again, we can consider scalar multiplication and division as complex
multiplication and division with a complex value of 0, or you can look at
multiplication of a scalar with a complex number to convince yourself this
is true

W = V * x; |W| = |V| * x; θW = θV
W = V / x; |W| = |V| / x; θW = θV

Thus, both vector and scalar multiplication/division operations are
isomorphic to complex multiplication/division.
Great!  We've come up with a mapping from complex numbers to vectors, as
we had hoped.

--------------------------------------------------------------------------
                VECTOR-SCALAR EXPONENTIATION
--------------------------------------------------------------------------

From vector-scalar multiplication and division, we can easily move to
vector-scalar exponentiation.
First, let's consider the definition of scalar exponentiation.

If W = V ^ n,
W = (V * V * ... * V) {n times}

I will copy again our definition of vector multiplication:
For two vectors V and W multiplied together, we get a resulting vector X
defined as follows:
X = V * W
|X| = |V| * |W|
θX = (θV + θW) mod 2pi

If W = V ^ n:
|W| = |V| * |V| * ... * |V| {n times}
θw = (θv + θv + ... + θv) {n times} mod 2pi

From our definition of vector multiplication, we can see that the
definition for vector exponentiation by a scalar is as follows:

--------------------------------------------------------------------------
                VECTOR-SCALAR EXPONENTIATION DEFINITION
--------------------------------------------------------------------------
If W = V ^ n:
|W| = |V| ^ n
θw = θv * n mod 2pi

note here that because the change in angle is a modular multiplicative
operation, we will not be able to "undo" this operation.  Take, for example,
θv = 3, n = 3.  Then, if W = V ^ 3, θw = θv * 3 mod 2pi = 9 mod 2pi ~2.72
Then, Z = W ^ 1/3 will give an angle of θz ~ 0.9, which is obviously not
equal to the original angle.  However, we can see that both vectors
Z and V raised to the third power do give W, so "inverse exponentiation"
is not a unique operation.

--------------------------------------------------------------------------
                    VECTOR-VECTOR EXPONENTIATION
--------------------------------------------------------------------------

http://scipp.ucsc.edu/~haber/ph116A/clog_11.pdf

Our system must meet the basic requirements of exponentiation:
https://mathinsight.org/exponentiation_basic_rules
(V ^ W) * (V ^ Y) = V ^ (W + Y)
(V ^ W) / (V ^ Y) = V ^ (W - Y)
(V ^ W) ^ Y) = V ^ (W * Y)
(V * W) ^ Y = (V ^ Y) * (W ^ Y)
V ^ I = V
V ^ 0 = I
V ^ (-I) = I / V
V ^ (-W) = I / (V ^ W)


Let us look at X = V ^ W, where W = (r * I), and r is any real number.
X = V ^ (r * I)
X = ((V ^ r) ^ I)
X = V ^ r
Therefore, exponentiation of a vector with no complex component is isomorphic to exponentiation of a scalar.
|X| = |V| ^ r
θx = θv * r

Next, let us look at a system of the form:
X = (V ^ W) where W = (m * I + n * I'); m and n are any real number
Let's say M = n * I and N' = n * I'
Then,
X = V ^ (M + N')
X = (V ^ M) * (V ^ N')
   = (V ^ M) * (V ^ (n * I'))
   = (V ^ M) * (V ^ n) * (V ^ I')
   = (V ^ m) * (V ^ n) * V ^ (I')
   = (V ^ (m * n)) * (V ^ I')
Let's define V' as V ^ (m * n)
X = (V' * V ^ I')
Therefore, if we can define V ^ I', we can define V ^ W for any two vectors V and W

Let us look at X = (V ^ W) ^ I', where W = r * I', and r is any real number
X = (V ^ (r * I')) ^ I'
X = V ^ (r * I' * I')
X = V ^ (-r * I)
Thus, (V ^ (r * I')) ^ I' is well-defined:

--------------------------------------------------------------------------
                    VECTOR EXPONENTIATION BY I' TWICE
--------------------------------------------------------------------------
V ^ (r * I') ^ I' = V ^ (-r * I)

(this is starting to look a lot like a sinusoid...)

If we can define an arbitrary vector W = V ^ r * I', we can therefore
fully define vector-vector exponentiation.

Let us look at (I * I') ^ I':
(I * I') ^ I' = (I ^ I') * (I' ^ I')
I' ^ I' = (I ^ I') * (I' ^ I')

--------------------------------------------------------------------------
                    EXPONENTIATION OF I BY I'
--------------------------------------------------------------------------
Therefore, I ^ I' = I

V ^ -I = V ^ I' * I' = (V ^ I') ^ I'



Let us look at the Taylor series expansion for E^I'

The Taylor series of a real or complex-valued function f(x) that is
infinitely differentiable at a real or complex number a is the power series

f(x+a) = f(a) + f'(a)/1!*(x-a) + f''(a)/2!*(x-a)^2 + f'''(a)/3!*(x-a)^3+...,

Let us look specifically at a = 0 - this is the Mclaurin series.

f(x+0) = f(0) + f'(0)*x/1! + f''(0)*x^2/2! = f'''(0)*x^3/3! + ... ,

So for a vector V, the Mclaurin series of F(V)=E^V is:

F(V) = E^0 + V * E^0/1! + V^2 * E^0/2! + V^3 * E^0/3!

We are here assuming that d/dV(E^V) = E^V * dV, we will need to prove this later.

F(V) = I + V/1! + V^2/2! + V^3/3! + ...

We will use this as a definition of E^V.  Basic testing indicates full convergence
at a series length of 18.

Testing this definition out yields some interesting results.

If F(V) = E^V:
F(n*I) = (e^n<0)
    this is as expected; vector arithmetic for "scalar vectors" is equivalent to scalar
    arithmetic
F(n*I') = (1<n)
    this is somewhat surprising, but does prove Euler's theorem in vector space:
    e^ix = cos(x) + i*sin(x)

Is it true that F'(x) = F(x)?
F'(x) = -sin(x) + i*cos(x)
From this, it is obvious that F(x) != F'(x)
Therefore, this derivation is invalid!!  Our assumption did not hold true!

So trying to derive this from "first principles" has not yet been successful.

Let's try to think of an alternative way to define the vector exponential function.

https://www.youtube.com/watch?v=m2MIpDrF7Es&t=56s
From this video, made by 3blue1brown, the exponential is a function whose definition
is related to rates of change in size - when the rate of change in size is proportional
to the current size.

How would that be similar for our exponential function?
Well, there are a few ways to define the "size" of a vector.  You could start with
the x and y coordinates, and exponentiate each of them, and say that the resulting
vector is the output of this exponential function.
Or, you could take the radius and angle of the vector, exponentiate each of them,
and say that the resulting vector is the output of this exponential function.
Or, you could exponentiate only the radius of the vector, holding the angle constant.
These three options will each give wildly different results.  How do we know
which, if any, is correct?

We now need to hold ourselves to the rules defined earlier, especially given our
rules of vector addition/subtraction and division/multiplication.

below is a list of rules our system must follow:

(V ^ W) * (V ^ Y) = V ^ (W + Y)
(V ^ W) / (V ^ Y) = V ^ (W - Y)
(V ^ W) ^ Y) = V ^ (W * Y)
(V * W) ^ Y = (V ^ Y) * (W ^ Y)
V ^ I = V
V ^ 0 = I
V ^ (-I) = I / V
V ^ (-W) = I / (V ^ W)
I ^ I' = I
V ^ (r * I') ^ I' = V ^ (-r * I)
E ** V = V.exp() << we defined the exponential using a Taylor series expansion;
we have programmed that internally to the Vector object in the vectorArithmetic.py module

Now, let us look in turn at each of our various proposed equivalents.

One problem that immediately pops out is that there is no version of "negative exponentiation"
since the magnitude of the vector is always positive.

In fact, upon further consideration, there is no version of "negative numbers" for vectors...

--------------------------------------------------------------------------
                    VECTOR-VECTOR LOGARITHM
--------------------------------------------------------------------------


Our system must meet the basic requirements of exponentiation:
https://mathinsight.org/exponentiation_basic_rules
LN(X * Y) = LN(X) + LN(Y)
LN(X / Y) = LN(X) - LN(Y)
LN(X ^ Y) = Y * LN(X)
LN(E) = I
LN(I) = 0
LN(I / X) = -LN(X)

Let us look at LN(V ^ I'):
LN(V ^ I') = I' * LN(V)


W^Z = (E^LN(W))^Z                                  <<E^LN(X) = X
W^Z = E^(Z * LN(W))                                <<(X^A)^B = X^(A*B)

If Z = I',
LN(W^Z) = Z * LN(W)
LN(W^I') = I' * LN(W)





Let us look at the Taylor

We will define exp(V) as the sum from k = 0 to infinity of V^k / k!:
exp(V) = I + V + 1/2!V^2 + 1/3!V^3 + ... (this is the Taylor Expansion)
e = exp(1) =  1 * Σ(1/k)! from k = 0 to infinity
Therefore, in vector notation, Ve = e * I; I will designate this E
E = e * I
E = (e, 0)
E = (e<0)

Now, let's consider E ^ r * I':
exp(I') = I + I' + 1/2 * I' ^2



Now, let us consider the natural logarithm function:
LN(E^V) = V
LogW(K) = LogE(K) / LogE(W)                        <<change of base rule: logb(x) = logd(x)/logd(b)
LogW(K) = LN(K) / LN(W)                            <<LogE(X) = LN(X)
LogI'(K) = LN(K) / LN(I')
LogI'(X) = V^(r*I') = LN(X) / LN(I')



What is a logarithm?  It's a function such that
logb(b^x) = x


W^Z = (E^LN(W))^Z                                  <<E^LN(X) = X
W^Z = E^(Z * LN(W))                                <<(X^A)^B = X^(A*B)
Suppose R=I*Rw and θ'=I'*θw; let's make the below guess
W = R*E^θ'                                         <<good guess from the guys who know the answer
W^Z = E^(Z*LN[R * E^θ'])                           <<substitution
W^Z = E^[Z*(LN[R] + LN[E^θ'])]                     <<LN(A*B) = LN(A) + LN(B)
W^Z = E^[Z*(LN[R]+θ')]                             <<LN(E^X) = X
W^Z = E^[Z*LN(R)+Z*(θ')]                           <<X*(A+B) = X*A + X*B
W^Z = E^[Z*LN(R)]*E^[Z*θ']                         <<X^(A+B) = (X^A)*(X^B)
W^Z = ([E^LN(R)]^Z)*E^[Z*θ']                       <<X^(A*B) = (X^A)^B
W^Z = (R^Z)*E^[Z*θ']                               <<LN(E^X) = X

W^Z = [(I*Rw)*E^(I'*θw)]^Z                         <<Exponentiating the above line by the vector Z
W^Z = E^[Z*LN(W)]                                  <<copied from the line before we defined W'


W' = LN(W)                                         <<copied from original definition
W' = LN[(I*Rw)*E^(I'*θw)]                          <<substitution
W' = LN(I*Rw) + LN(E^(I'*θw))                      <<Ln(A*B) = Ln(A)+Ln(B)
W' = LN(I*Rw) + I'*θw				               <<Ln(E^(X)) = X
W = E^(W')					                       <<copied from above
W = E^[LN(I*Rw) + I'*θw]                           <<substituting W'


W = (I*Rw)*E^(I'*θw)                               <<good guess from the guys who know the answer
W^Z = [(I*Rw)   * E^(I'*θw)]^Z                     <<Exponentiating the above line by the vector Z
W^Z = E^(Z * LN(W))                                   <<copied from above
